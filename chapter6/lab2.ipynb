{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Lab 2 - Ridge Regression and the Lasso\n",
    "\n",
    "Notes - If you do not have a fortran compiler...Get one. Follow step \n",
    "[here](https://www.youtube.com/watch?v=xuQL_BZydS0)\n",
    "\n",
    "NOTES - Standardize is NOT Normalize\n",
    "\n",
    "#### Import block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.preprocessing import scale"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are using the exact same data as in lab 1 with removal of all None values\n",
    "\n",
    "Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_path = 'D:\\\\PycharmProjects\\\\ISLR\\\\data\\\\'\n",
    "hitter = pd.read_csv(f'{data_path}Hitters.csv', index_col=0, na_values='NA').dropna()\n",
    "\n",
    "# Transform categorical variables into dummy\n",
    "for i in ['League', 'Division', 'NewLeague']:\n",
    "    hitter[i] = hitter[i].astype('category').cat.codes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 6.6.1 - Ridge Regression\n",
    "\n",
    "There are some important points before we proceed. \n",
    "1. Standardizing is what we will perform NOT normalizing. \n",
    "2. alpha/lambda used in sklearn package follows the formula in the book while glmnet does not.\n",
    "3. Use MSE to compare the end result is the surefire way to understand this."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "                   MSE\nalpha=4  102375.707696\nalpha=0  116690.468567\nOLS      116690.468567",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MSE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>alpha=4</td>\n      <td>102375.707696</td>\n    </tr>\n    <tr>\n      <td>alpha=0</td>\n      <td>116690.468567</td>\n    </tr>\n    <tr>\n      <td>OLS</td>\n      <td>116690.468567</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 4
    }
   ],
   "source": [
    "# Setting seed for reproducible\n",
    "np.random.seed(1)\n",
    "\n",
    "# Initialized and standardize X - NOT y\n",
    "t_prop = 0.5\n",
    "y = hitter.Salary\n",
    "X = hitter.drop('Salary', axis=1)\n",
    "\n",
    "X_scaled = scale(X)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y.ravel(), test_size=t_prop)\n",
    "\n",
    "# Fit Ridge regression\n",
    "score_dict = {}\n",
    "for i in [4, 0]:\n",
    "    ridge = skl_lm.Ridge(alpha=i,fit_intercept=True).fit(X_train, y_train)\n",
    "    pred = ridge.predict(X_test)\n",
    "    score_dict[f'alpha={i}'] = mean_squared_error(y_test, pred)\n",
    "\n",
    "# Fit OLS\n",
    "regr = skl_lm.LinearRegression(fit_intercept=True).fit(X_train, y_train)\n",
    "pred = regr.predict(X_test)\n",
    "score_dict['OLS'] = mean_squared_error(y_test, pred)\n",
    "\n",
    "# Return dataframe\n",
    "pd.DataFrame.from_dict(score_dict, orient='index', columns=['MSE'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We get the result that is kinda similar to the book. (Differences are in how we split the data). \n",
    "Nevertheless, OLS result is the same as alpha = 0. \n",
    "\n",
    "Now we will use RidgeCV to get the best fit for our model. RidgeCV to the rescue"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Best alpha/lambda:  214.21421421421422\nAtBat        11.789680\nHits         28.059029\nHmRun         7.833336\nRuns         19.611866\nRBI          26.932623\nWalks        34.214407\nYears        12.372675\nCAtBat       20.348077\nCHits        27.732906\nCHmRun       33.721081\nCRuns        27.651778\nCRBI         34.991083\nCWalks       22.682022\nLeague        5.187553\nDivision    -28.433171\nPutOuts      54.174106\nAssists      -1.400036\nErrors        1.001642\nNewLeague     4.207332\ndtype: float64\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "d:\\pycharmprojects\\islr\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n  DeprecationWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "ridgeCV = skl_lm.RidgeCV(alphas=np.linspace(0, 1000, num=1000), fit_intercept=True, cv=10).fit(X_train, y_train)\n",
    "print('Best alpha/lambda: ', ridgeCV.alpha_)\n",
    "\n",
    "# Print coefficient\n",
    "print(pd.Series(ridgeCV.coef_, index=X.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "None of the coefficient is at 0. Ridge does not perform feature selection! \n",
    "The best alpha seems to be 214 (compared to 212 in the book). We can calculate MSE"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "         alpha=214\nMSE  100416.083138",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alpha=214</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>MSE</td>\n      <td>100416.083138</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 6
    }
   ],
   "source": [
    "ridge = skl_lm.Ridge(alpha=214, fit_intercept=True).fit(X_train, y_train)\n",
    "pred = ridge.predict(X_test)\n",
    "pd.DataFrame.from_dict({'MSE':mean_squared_error(y_test, pred)}, \n",
    "                       orient='index', columns=['alpha=214'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notes: I did not run and get the parameters as it will not be the same as in the book.\n",
    "\n",
    "### 6.6.2 - The Lasso\n",
    "\n",
    "The main advantage of The Lasso over Ridge is interpretability. The Lass also performs\n",
    "feature selection for us.\n",
    "\n",
    "First, we will let alpha = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "               alpha=1\nalpha=0  106603.291383",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>alpha=1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>alpha=0</td>\n      <td>106603.291383</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "# The Lasso\n",
    "score_dict = {}\n",
    "lasso = skl_lm.Lasso(alpha=1, fit_intercept=True, max_iter=10000).fit(X_train, y_train)\n",
    "pred = lasso.predict(X_test)\n",
    "score_dict[f'alpha={i}'] = mean_squared_error(y_test, pred)\n",
    "    \n",
    "pd.DataFrame.from_dict(score_dict, orient='index', columns=['alpha=1'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We already get a much better MSE value using only alpha=1. Now lets use crossvalidation\n",
    "to find the best alpha. (max_iter is there to ensure convergence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Best alpha/lambda for lasso is: 28.038544563299862\n\nAtBat          0.000000\nHits          47.417650\nHmRun          0.000000\nRuns           0.000000\nRBI            0.000000\nWalks         64.015609\nYears          0.000000\nCAtBat         0.000000\nCHits          0.000000\nCHmRun        16.244204\nCRuns          0.000000\nCRBI         168.983059\nCWalks         0.000000\nLeague         0.000000\nDivision     -43.965445\nPutOuts      104.196353\nAssists       -0.000000\nErrors        -0.000000\nNewLeague      0.000000\ndtype: float64\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Run the lassoCV\n",
    "lassoCV = skl_lm.LassoCV(alphas=None, fit_intercept=True, cv=10, max_iter=100000)\n",
    "lassoCV.fit(X_train, y_train)\n",
    "print(f'Best alpha/lambda for lasso is: {lassoCV.alpha_}\\n')\n",
    "print(pd.Series(lassoCV.coef_, index=X.columns))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "There are only 6 variables (not including intercept) with coefficient different from zero. \n",
    "However, we get one less variable than the book: LeagueN. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
