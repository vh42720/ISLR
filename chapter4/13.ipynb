{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Applied - Question 13\n",
    "\n",
    "The question involve Boston dataset - a data frame with 506 observations and 14 variables.\n",
    "The data was originally published by Harrison, \n",
    "D. and Rubinfeld, D.L. `Hedonic prices and the demand for clean air', \n",
    "J. Environ. Economics & Management, vol.5, 81-102, 1978.\n",
    "\n",
    "There are 14 attributes in each case of the dataset. They are:\n",
    "\n",
    "  1. CRIM - per capita crime rate by town  \n",
    "  2. ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "  3. INDUS - proportion of non-retail business acres per town.\n",
    "  4. CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "  5. NOX - nitric oxides concentration (parts per 10 million)\n",
    "  6. RM - average number of rooms per dwelling\n",
    "  7. AGE - proportion of owner-occupied units built prior to 1940\n",
    "  8. DIS - weighted distances to five Boston employment centres\n",
    "  9. RAD - index of accessibility to radial highways\n",
    "  10. TAX - full-value property-tax rate per $10,000\n",
    "  11. PTRATIO - pupil-teacher ratio by town\n",
    "  12. B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "  13. LSTAT - % lower status of the population\n",
    "  14. MEDV - Median value of owner-occupied homes in $1000's\n",
    "\n",
    "We will try to classify whether a given suburb has a crim rate above or below the median.\n",
    "\n",
    "### [Part I](#part1) : Correct way to do this!  \n",
    "### [Part II](#part2) : How I am so wrong!\n",
    "\n",
    "Import block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import preprocessing, neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from util import print_cm\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "             crim          zn       indus        chas         nox          rm  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \nstd      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \nmin      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n75%      3.677082   12.500000   18.100000    0.000000    0.624000    6.623500   \nmax     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n\n              age         dis         rad         tax     ptratio       black  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \nstd     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \nmin      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \nmax    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n\n            lstat        medv  \ncount  506.000000  506.000000  \nmean    12.653063   22.532806  \nstd      7.141062    9.197104  \nmin      1.730000    5.000000  \n25%      6.950000   17.025000  \n50%     11.360000   21.200000  \n75%     16.955000   25.000000  \nmax     37.970000   50.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>crim</th>\n      <th>zn</th>\n      <th>indus</th>\n      <th>chas</th>\n      <th>nox</th>\n      <th>rm</th>\n      <th>age</th>\n      <th>dis</th>\n      <th>rad</th>\n      <th>tax</th>\n      <th>ptratio</th>\n      <th>black</th>\n      <th>lstat</th>\n      <th>medv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>count</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n    </tr>\n    <tr>\n      <td>mean</td>\n      <td>3.613524</td>\n      <td>11.363636</td>\n      <td>11.136779</td>\n      <td>0.069170</td>\n      <td>0.554695</td>\n      <td>6.284634</td>\n      <td>68.574901</td>\n      <td>3.795043</td>\n      <td>9.549407</td>\n      <td>408.237154</td>\n      <td>18.455534</td>\n      <td>356.674032</td>\n      <td>12.653063</td>\n      <td>22.532806</td>\n    </tr>\n    <tr>\n      <td>std</td>\n      <td>8.601545</td>\n      <td>23.322453</td>\n      <td>6.860353</td>\n      <td>0.253994</td>\n      <td>0.115878</td>\n      <td>0.702617</td>\n      <td>28.148861</td>\n      <td>2.105710</td>\n      <td>8.707259</td>\n      <td>168.537116</td>\n      <td>2.164946</td>\n      <td>91.294864</td>\n      <td>7.141062</td>\n      <td>9.197104</td>\n    </tr>\n    <tr>\n      <td>min</td>\n      <td>0.006320</td>\n      <td>0.000000</td>\n      <td>0.460000</td>\n      <td>0.000000</td>\n      <td>0.385000</td>\n      <td>3.561000</td>\n      <td>2.900000</td>\n      <td>1.129600</td>\n      <td>1.000000</td>\n      <td>187.000000</td>\n      <td>12.600000</td>\n      <td>0.320000</td>\n      <td>1.730000</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <td>25%</td>\n      <td>0.082045</td>\n      <td>0.000000</td>\n      <td>5.190000</td>\n      <td>0.000000</td>\n      <td>0.449000</td>\n      <td>5.885500</td>\n      <td>45.025000</td>\n      <td>2.100175</td>\n      <td>4.000000</td>\n      <td>279.000000</td>\n      <td>17.400000</td>\n      <td>375.377500</td>\n      <td>6.950000</td>\n      <td>17.025000</td>\n    </tr>\n    <tr>\n      <td>50%</td>\n      <td>0.256510</td>\n      <td>0.000000</td>\n      <td>9.690000</td>\n      <td>0.000000</td>\n      <td>0.538000</td>\n      <td>6.208500</td>\n      <td>77.500000</td>\n      <td>3.207450</td>\n      <td>5.000000</td>\n      <td>330.000000</td>\n      <td>19.050000</td>\n      <td>391.440000</td>\n      <td>11.360000</td>\n      <td>21.200000</td>\n    </tr>\n    <tr>\n      <td>75%</td>\n      <td>3.677082</td>\n      <td>12.500000</td>\n      <td>18.100000</td>\n      <td>0.000000</td>\n      <td>0.624000</td>\n      <td>6.623500</td>\n      <td>94.075000</td>\n      <td>5.188425</td>\n      <td>24.000000</td>\n      <td>666.000000</td>\n      <td>20.200000</td>\n      <td>396.225000</td>\n      <td>16.955000</td>\n      <td>25.000000</td>\n    </tr>\n    <tr>\n      <td>max</td>\n      <td>88.976200</td>\n      <td>100.000000</td>\n      <td>27.740000</td>\n      <td>1.000000</td>\n      <td>0.871000</td>\n      <td>8.780000</td>\n      <td>100.000000</td>\n      <td>12.126500</td>\n      <td>24.000000</td>\n      <td>711.000000</td>\n      <td>22.000000</td>\n      <td>396.900000</td>\n      <td>37.970000</td>\n      <td>50.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 5
    }
   ],
   "source": [
    "data_path = 'D:\\\\PycharmProjects\\\\ISLR\\\\data\\\\'\n",
    "boston = pd.read_csv(f'{data_path}Boston.csv')\n",
    "boston.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "     zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio   black  \\\n0  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3  396.90   \n1   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8  396.90   \n2   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8  392.83   \n3   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7  394.63   \n4   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7  396.90   \n\n   lstat  medv  crim01  \n0   4.98  24.0       0  \n1   9.14  21.6       0  \n2   4.03  34.7       0  \n3   2.94  33.4       0  \n4   5.33  36.2       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>zn</th>\n      <th>indus</th>\n      <th>chas</th>\n      <th>nox</th>\n      <th>rm</th>\n      <th>age</th>\n      <th>dis</th>\n      <th>rad</th>\n      <th>tax</th>\n      <th>ptratio</th>\n      <th>black</th>\n      <th>lstat</th>\n      <th>medv</th>\n      <th>crim01</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1</td>\n      <td>296</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>24.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>21.6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>34.7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>33.4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>36.2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 8
    }
   ],
   "source": [
    "df = pd.DataFrame.copy(boston, deep=True)\n",
    "median_value = np.median(df.crim)\n",
    "df['crim01'] = np.where(df['crim'] > median_value, 1, 0)\n",
    "df = df.drop('crim', axis=1)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We learned from exercise 15 of chapter 3, putting all of our variables in the model will\n",
    "result in most of tem statistically insignificant. Thus, I thought to use only significant \n",
    "ones:\n",
    " 1. zn\n",
    " 2. dis\n",
    " 3. rad\n",
    " 4. black\n",
    " 5. medv\n",
    "\n",
    "Nevertheless, we will proceed with the full dataset in the first part and the 5 variables\n",
    "mentioned above in the second part.\n",
    "Lets start with splitting 60% train, 40% test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "X = df.drop('crim01', axis=1)\n",
    "y = df.crim01\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='part1'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part 1: All features classification\n",
    "\n",
    "#### Logistic Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix \n True        0   1\nPredicted        \n0          91  18\n1          10  84 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.835     0.901     0.867       101\n           1      0.894     0.824     0.857       102\n\n    accuracy                          0.862       203\n   macro avg      0.864     0.862     0.862       203\nweighted avg      0.864     0.862     0.862       203\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "regr = skl_lm.LogisticRegression(solver='newton-cg')\n",
    "pred = regr.fit(X_train, y_train).predict(X_test)\n",
    "print_cm(y_test, pred, regr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We get 0.862 accuracy rate which is not too bad considering how we choose our features\n",
    "which is everything!\n",
    "\n",
    "#### LDA Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix \n True        0   1\nPredicted        \n0          94  22\n1           7  80 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.810     0.931     0.866       101\n           1      0.920     0.784     0.847       102\n\n    accuracy                          0.857       203\n   macro avg      0.865     0.858     0.856       203\nweighted avg      0.865     0.857     0.856       203\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "pred = lda.fit(X_train, y_train).predict(X_test)\n",
    "print_cm(y_test, pred, lda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LDA gives us a similar results at 0.857 accuracy/\n",
    "\n",
    "#### QDA Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix \n True         0   1\nPredicted         \n0          100  18\n1            1  84 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.847     0.990     0.913       101\n           1      0.988     0.824     0.898       102\n\n    accuracy                          0.906       203\n   macro avg      0.918     0.907     0.906       203\nweighted avg      0.918     0.906     0.906       203\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "pred = qda.fit(X_train, y_train).predict(X_test)\n",
    "print_cm(y_test, pred, qda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wow QDA gives a stunning results with 0.906 accuracy and 0.99 specificity (avoidance of false\n",
    "positive).\n",
    "\n",
    "Lets try KNN with K = 1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix \n True        0   1\nPredicted        \n0          93   7\n1           8  95 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.930     0.921     0.925       101\n           1      0.922     0.931     0.927       102\n\n    accuracy                          0.926       203\n   macro avg      0.926     0.926     0.926       203\nweighted avg      0.926     0.926     0.926       203\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print_cm(y_test, pred, knn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While our specificity takes a hit at 0.921, our accuracy improves by nearly 0.02 to \n",
    "0.926. \n",
    "\n",
    "KNN with K = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix \n True        0   1\nPredicted        \n0          94   9\n1           7  93 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.913     0.931     0.922       101\n           1      0.930     0.912     0.921       102\n\n    accuracy                          0.921       203\n   macro avg      0.921     0.921     0.921       203\nweighted avg      0.921     0.921     0.921       203\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print_cm(y_test, pred, knn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems like increasing K in this case is not a good idea.\n",
    "\n",
    "KNN with K = 10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix \n True        0   1\nPredicted        \n0          92  17\n1           9  85 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.844     0.911     0.876       101\n           1      0.904     0.833     0.867       102\n\n    accuracy                          0.872       203\n   macro avg      0.874     0.872     0.872       203\nweighted avg      0.874     0.872     0.872       203\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print_cm(y_test, pred, knn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another step back from increasing K. Lets use K = 3 as the best approx for KNN method."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id='part2'></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Part II: Using only 5 variables\n",
    "Our predictors :\n",
    " 1. zn\n",
    " 2. dis\n",
    " 3. rad\n",
    " 4. black\n",
    " 5. medv\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "X = df[['zn', 'dis','rad','black','medv']]\n",
    "y = df.crim01\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Logistic Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix \n True        0   1\nPredicted        \n0          88  25\n1          13  77 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.779     0.871     0.822       101\n           1      0.856     0.755     0.802       102\n\n    accuracy                          0.813       203\n   macro avg      0.817     0.813     0.812       203\nweighted avg      0.817     0.813     0.812       203\n\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "d:\\pycharmprojects\\islr\\venv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "regr = skl_lm.LogisticRegression()\n",
    "pred = regr.fit(X_train, y_train).predict(X_test)\n",
    "print_cm(y_test, pred, regr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Hrm! we get a bit worse result with using only 5 variables.\n",
    "\n",
    "Our accuracy drop down from 0.82 to 0.813 - not a big difference. \n",
    "\n",
    "#### LDA Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix \n True        0   1\nPredicted        \n0          93  23\n1           8  79 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.802     0.921     0.857       101\n           1      0.908     0.775     0.836       102\n\n    accuracy                          0.847       203\n   macro avg      0.855     0.848     0.847       203\nweighted avg      0.855     0.847     0.847       203\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis()\n",
    "pred = lda.fit(X_train, y_train).predict(X_test)\n",
    "print_cm(y_test, pred, lda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again we get a drop in accuracy from 0.857 to 0.847.\n",
    "\n",
    "#### QDA model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Confusion Matrix \n True        0   1\nPredicted        \n0          96  31\n1           5  71 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.756     0.950     0.842       101\n           1      0.934     0.696     0.798       102\n\n    accuracy                          0.823       203\n   macro avg      0.845     0.823     0.820       203\nweighted avg      0.845     0.823     0.820       203\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "pred = qda.fit(X_train, y_train).predict(X_test)\n",
    "print_cm(y_test, pred, qda)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This time we get a much worse result. Our accuracy drops nearly 0.10. The omission of\n",
    "many features/predictors hinders the flexibility of QDA to capture non linear relationship\n",
    "\n",
    "#### KNN with K = 1, 3, 5 and 7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "For K = 1\n\nConfusion Matrix \n True        0   1\nPredicted        \n0          89  17\n1          12  85 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.840     0.881     0.860       101\n           1      0.876     0.833     0.854       102\n\n    accuracy                          0.857       203\n   macro avg      0.858     0.857     0.857       203\nweighted avg      0.858     0.857     0.857       203\n\n\nFor K = 2\n\nConfusion Matrix \n True        0   1\nPredicted        \n0          94  28\n1           7  74 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.770     0.931     0.843       101\n           1      0.914     0.725     0.809       102\n\n    accuracy                          0.828       203\n   macro avg      0.842     0.828     0.826       203\nweighted avg      0.842     0.828     0.826       203\n\n\nFor K = 5\n\nConfusion Matrix \n True        0   1\nPredicted        \n0          89  15\n1          12  87 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.856     0.881     0.868       101\n           1      0.879     0.853     0.866       102\n\n    accuracy                          0.867       203\n   macro avg      0.867     0.867     0.867       203\nweighted avg      0.867     0.867     0.867       203\n\n\nFor K = 10\n\nConfusion Matrix \n True        0   1\nPredicted        \n0          92  27\n1           9  75 \n\nClassification report \n               precision    recall  f1-score   support\n\n           0      0.773     0.911     0.836       101\n           1      0.893     0.735     0.806       102\n\n    accuracy                          0.823       203\n   macro avg      0.833     0.823     0.821       203\nweighted avg      0.833     0.823     0.821       203\n\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for i in [1, 2, 5, 10]:\n",
    "    print(f'For K = {i}\\n')\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=i)\n",
    "    pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "    print_cm(y_test, pred, knn)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Again, seems like I was wrong to omit many other features from our dataset!\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
